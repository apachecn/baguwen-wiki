<!--yml
category: 未分类
date: 0001-01-01 00:00:00
--->

# Nginx多进程模型是如何实现高并发的？

> 原文：[https://zwmst.com/1701.html](https://zwmst.com/1701.html)

   [ *Java高并发* ](https://zwmst.com/java%e9%ab%98%e5%b9%b6%e5%8f%91)*[ <time datetime="2021-08-15T16:15:42+08:00"> 2021-08-15 </time> ](https://zwmst.com/1701.html)  进程数与并发数不存在很直接的关系。这取决取server采用的工作方式。如果一个server采用 一个进程负责一个request的方式，那么进程数就是并发数。那么显而易见的，就是会有很多 进程在等待中。等什么？最多的应该是等待网络传输。

Nginx的异步非阻塞工作方式正是利用了这点等待的时间。在需要等待的时候，这些进程就空 闲出来待命了。因此表现为少数几个进程就解决了大量的并发问题。apache是如何利用的呢， 简单来说：同样的4个进程，如果采用一个进程负责一个request的方式，那么，同时进来4个 request之后，每个进程就负责其中一个，直至会话关闭。期间，如果有第5个request进来了。就无法及时反应了，因为4个进程都没干完活呢，因此，一般有个调度进程，每当新进来了一个request，就新开个进程来处理。nginx不这样，每进来一个request，会有一个worker进程去处理。但不是全程的处理，处理到什么程度呢？处理到可能发生阻塞的地方，比 如向上游（后端）服务器转发request，并等待请求返回。那么，这个处理的worker不会这么 傻等着，他会在发送完请求后，注册一个事件：“如果upstream返回了，告诉我一声，我再接 着干”。于是他就休息去了。此时，如果再有request进来，他就可以很快再按这种方式处理。 而一旦上游服务器返回了，就会触发这个事件，worker才会来接手，这个request才会接着往 下走。由于web server的工作性质决定了每个request的大部份生命都是在网络传输中，实际 上花费在server机器上的时间片不多。这是几个进程就解决高并发的秘密所在。webserver刚 好属于网络io密集型应用，不算是计算密集型。异步，非阻塞，使用epoll，和大量细节处的优 化。也正是nginx之所以然的技术基石。*